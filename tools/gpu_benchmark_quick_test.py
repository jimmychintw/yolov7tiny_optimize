#!/usr/bin/env python3
"""
GPU å¿«é€Ÿæ¸¬è©¦è…³æœ¬ - ç”¨æ–¼é©—è­‰ç¨‹å¼ç¢¼æ˜¯å¦æ­£å¸¸é‹ä½œ
"""

import torch
import sys
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))

def quick_test():
    """å¿«é€Ÿæ¸¬è©¦ä¸»è¦åŠŸèƒ½"""
    print("ğŸ” é–‹å§‹å¿«é€Ÿæ¸¬è©¦...")
    
    # 1. æª¢æŸ¥ CUDA
    print(f"âœ… CUDA å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    
    # 2. æª¢æŸ¥å¿…è¦å¥—ä»¶
    packages = []
    try:
        import GPUtil
        packages.append("âœ… GPUtil")
    except ImportError:
        packages.append("âŒ GPUtil (éœ€è¦: pip install gputil)")
    
    try:
        from tqdm import tqdm
        packages.append("âœ… tqdm")
    except ImportError:
        packages.append("âŒ tqdm (éœ€è¦: pip install tqdm)")
    
    try:
        from models.yolo import Model
        packages.append("âœ… YOLOv7 Model")
    except ImportError as e:
        packages.append(f"âŒ YOLOv7 Model: {e}")
    
    try:
        from utils.loss import ComputeLoss
        packages.append("âœ… ComputeLoss")
    except ImportError as e:
        packages.append(f"âŒ ComputeLoss: {e}")
    
    print("\nğŸ“¦ å¥—ä»¶æª¢æŸ¥:")
    for p in packages:
        print(f"   {p}")
    
    # 3. æ¸¬è©¦æ¨¡å‹å»ºç«‹
    if all("âœ…" in p for p in packages[:4]):
        print("\nğŸ—ï¸  æ¸¬è©¦æ¨¡å‹å»ºç«‹...")
        try:
            from models.yolo import Model
            from utils.loss import ComputeLoss
            import yaml
            
            model = Model("cfg/training/yolov7-tiny.yaml", ch=3, nc=80).cuda()
            
            # è¼‰å…¥è¶…åƒæ•¸
            with open("data/hyp.scratch.tiny.yaml", 'r') as f:
                hyp = yaml.safe_load(f)
            model.hyp = hyp
            
            compute_loss = ComputeLoss(model)
            
            # æ¸¬è©¦å‰å‘å‚³æ’­
            dummy_input = torch.randn(1, 3, 320, 320).cuda()
            with torch.cuda.amp.autocast():
                outputs = model(dummy_input)
            
            print("âœ… æ¨¡å‹å‰å‘å‚³æ’­æˆåŠŸ")
            
            # æ¸¬è©¦ loss è¨ˆç®—
            dummy_targets = torch.tensor([[0, 0, 0.5, 0.5, 0.2, 0.3]], dtype=torch.float32).cuda()
            loss, _ = compute_loss(outputs, dummy_targets)
            print(f"âœ… Loss è¨ˆç®—æˆåŠŸ: {loss.item():.4f}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹æ¸¬è©¦å¤±æ•—: {e}")
    
    print("\nâœ¨ å¿«é€Ÿæ¸¬è©¦å®Œæˆï¼")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰ä»»ä½•å¤±æ•—
    if any("âŒ" in p for p in packages):
        print("\nâš ï¸  è«‹å…ˆå®‰è£ç¼ºå°‘çš„å¥—ä»¶å†åŸ·è¡Œå®Œæ•´æ¸¬è©¦")
        return False
    return True

if __name__ == "__main__":
    success = quick_test()
    if success:
        print("\nğŸ’¡ å¯ä»¥åŸ·è¡Œå®Œæ•´æ¸¬è©¦:")
        print("   python tools/gpu_benchmark.py --quick")