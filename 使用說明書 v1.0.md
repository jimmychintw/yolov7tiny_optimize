# YOLOv7-tiny Baseline ä½¿ç”¨èªªæ˜æ›¸ v1.0

**ç‰ˆæœ¬**: v1.0  
**æ—¥æœŸ**: 2025-08-14  
**é©ç”¨**: YOLOv7-tiny Baseline å°ˆæ¡ˆ  
**PRD ç‰ˆæœ¬**: v1.4

---

## ğŸ“‹ ç›®éŒ„

1. [å°ˆæ¡ˆæ¦‚è¿°](#å°ˆæ¡ˆæ¦‚è¿°)
2. [ç³»çµ±éœ€æ±‚](#ç³»çµ±éœ€æ±‚)
3. [å®‰è£æŒ‡å—](#å®‰è£æŒ‡å—)
4. [è³‡æ–™æº–å‚™](#è³‡æ–™æº–å‚™)
5. [åŸºç¤è¨“ç·´](#åŸºç¤è¨“ç·´)
6. [å¯¦é©—ç³»çµ±](#å¯¦é©—ç³»çµ±)
7. [ç›£æ§èˆ‡åˆ†æ](#ç›£æ§èˆ‡åˆ†æ)
8. [æ¨¡å‹å°å‡ºèˆ‡é‡åŒ–](#æ¨¡å‹å°å‡ºèˆ‡é‡åŒ–)
9. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
10. [é™„éŒ„](#é™„éŒ„)

---

## ğŸ¯ å°ˆæ¡ˆæ¦‚è¿°

### å°ˆæ¡ˆç›®æ¨™
æœ¬å°ˆæ¡ˆå¯¦ä½œ YOLOv7-tiny æ¨¡å‹çš„å®Œæ•´è¨“ç·´èˆ‡é‡åŒ– Pipelineï¼Œå°ˆæ³¨æ–¼åœ¨ COCO2017 è³‡æ–™é›†ä¸Šé€²è¡Œ 320Ã—320 è¼¸å…¥å°ºå¯¸çš„è¨“ç·´ã€‚å°ˆæ¡ˆåš´æ ¼éµå¾ª PRD v1.4 è¦ç¯„ï¼Œç¢ºä¿çµæœçš„å¯é‡ç¾æ€§èˆ‡æ¨™æº–åŒ–ã€‚

### æ ¸å¿ƒç‰¹è‰²
- **å¾é ­è¨“ç·´**: ä½¿ç”¨éš¨æ©Ÿæ¬Šé‡åˆå§‹åŒ–ï¼Œä¸ä¾è³´é è¨“ç·´æ¨¡å‹
- **AMP è¨“ç·´**: æ”¯æ´ FP16 æ··åˆç²¾åº¦è¨“ç·´ï¼Œæå‡æ•ˆç‡
- **å¤š GPU æ”¯æ´**: é‡å° RTX 4090/5090ã€H100ã€B200 å„ªåŒ–
- **å®Œæ•´å¯¦é©—ç³»çµ±**: æ•ˆèƒ½æ¸¬è©¦ã€å¯¦é©—ç®¡ç†ã€çµæœæ¯”è¼ƒ
- **PTQ é‡åŒ–**: ONNX Runtime éœæ…‹é‡åŒ–æ”¯æ´
- **PRD åˆè¦**: åš´æ ¼éµå¾ª PRD v1.4 æ‰€æœ‰è¦ç¯„

### é æœŸçµæœ
- **FP16 ç²¾åº¦**: mAP@0.5:0.95 ç´„ 32-34
- **INT8 é‡åŒ–**: ç›¸æ¯” FP16 æ‰é» 1.5-3.0 mAP
- **è·¨å¹³å°ä¸€è‡´æ€§**: å„å¼•æ“å·®ç•° â‰¤ 0.5 mAP

### GPU æ•ˆèƒ½åŸºæº– (v2.0 æ“¬çœŸæ¸¬è©¦)
| GPU | æœ€ä½³ FPS | æ¥µé™ Batch Size | ç›¸å°æ•ˆèƒ½ |
|-----|----------|------------------|----------|
| RTX 4090 | ~2,200 | 768-1024 | 1.0Ã— |
| RTX 5090 | ~2,900 | 1024-1280 | 1.3Ã— |
| H100 | ~5,500 | 1536-2048 | 2.5Ã— |
| B200 | ~9,000 | 2560-4096 | 4.0Ã— |

---

## ğŸ–¥ï¸ ç³»çµ±éœ€æ±‚

### ç¡¬é«”éœ€æ±‚

#### æœ€ä½éœ€æ±‚
- **GPU**: NVIDIA GTX 1660 æˆ–ä»¥ä¸Š (6GB VRAM)
- **CPU**: 4 æ ¸å¿ƒæˆ–ä»¥ä¸Š
- **è¨˜æ†¶é«”**: 16GB RAM
- **å„²å­˜**: 100GB å¯ç”¨ç©ºé–“

#### å»ºè­°éœ€æ±‚
- **GPU**: RTX 4090 (24GB) æˆ–ä»¥ä¸Š
- **CPU**: 8 æ ¸å¿ƒæˆ–ä»¥ä¸Š
- **è¨˜æ†¶é«”**: 32GB RAM
- **å„²å­˜**: 200GB SSD

#### æ”¯æ´çš„é«˜éš GPU
| GPU å‹è™Ÿ | è¨˜æ†¶é«” | å»ºè­° Batch Size | é ä¼°è¨“ç·´æ™‚é–“ |
|----------|--------|-----------------|--------------|
| RTX 4090 | 24GB | 128-256 | ~48 å°æ™‚ |
| RTX 5090 | 32GB | 256-320 | ~36 å°æ™‚ |
| H100 | 80GB | 512-640 | ~24 å°æ™‚ |
| B200 | 192GB | 1024-1280 | ~18 å°æ™‚ |

### è»Ÿé«”éœ€æ±‚
- **ä½œæ¥­ç³»çµ±**: Ubuntu 18.04+ / CentOS 7+ / Windows 10+
- **Python**: 3.8-3.11
- **CUDA**: 11.8+ (æ”¯æ´æ‚¨çš„ GPU)
- **Docker**: å¯é¸ï¼Œç”¨æ–¼å®¹å™¨åŒ–éƒ¨ç½²

---

## ğŸš€ å®‰è£æŒ‡å—

### æ­¥é©Ÿ 1: ç’°å¢ƒæº–å‚™

#### 1.1 å…‹éš†å°ˆæ¡ˆ
```bash
# æ–¹å¼ 1: å¦‚æœæ‚¨æœ‰å°ˆæ¡ˆ Git å€‰åº«
git clone [your-repository-url]
cd yolov7tiny_baseline

# æ–¹å¼ 2: å¦‚æœä½¿ç”¨ç¾æœ‰ YOLOv7 å€‰åº«
git clone https://github.com/WongKinYiu/yolov7.git yolov7tiny_baseline
cd yolov7tiny_baseline
```

#### 1.2 å»ºç«‹è™›æ“¬ç’°å¢ƒ
```bash
# ä½¿ç”¨ conda (æ¨è–¦)
conda create -n yolov7tiny python=3.9
conda activate yolov7tiny

# æˆ–ä½¿ç”¨ venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows
```

### æ­¥é©Ÿ 2: å®‰è£ç›¸ä¾å¥—ä»¶

#### 2.1 åŸºç¤å¥—ä»¶
```bash
# å®‰è£ PyTorch (æ ¹æ“šæ‚¨çš„ CUDA ç‰ˆæœ¬èª¿æ•´)
ï¼ˆrunpod ä¸éœ€è¦ï¼Œä¸è¦è£ï¼ï¼ï¼)

# å®‰è£å…¶ä»–ç›¸ä¾å¥—ä»¶
pip install -r requirements.txt
```

#### 2.2 å¯¦é©—ç³»çµ±é¡å¤–å¥—ä»¶
```bash
# ç›£æ§å·¥å…·
pip install GPUtil psutil

# è³‡æ–™åˆ†æèˆ‡è¦–è¦ºåŒ–
pip install matplotlib seaborn pandas openpyxl

# ONNX ç›¸é—œ (ç”¨æ–¼æ¨¡å‹å°å‡º)
pip install onnx onnxsim onnxruntime
```

#### 2.3 é©—è­‰å®‰è£
```bash
python -c "import torch; print('PyTorch:', torch.__version__); print('CUDA available:', torch.cuda.is_available())"
```

### æ­¥é©Ÿ 3: è¨­å®š CLAUDE.md
å°‡æä¾›çš„ CLAUDE.md æª”æ¡ˆæ”¾ç½®æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼Œç¢ºä¿ AI åŠ©æ‰‹èƒ½æ­£ç¢ºç†è§£å°ˆæ¡ˆéœ€æ±‚ã€‚

---

## ğŸ“‚ è³‡æ–™æº–å‚™

### è³‡æ–™é›†çµæ§‹

å°ˆæ¡ˆä½¿ç”¨æ¨™æº–çš„å¹³è¡Œç›®éŒ„çµæ§‹ï¼š

```
/workspace/                  # å·¥ä½œå€æ ¹ç›®éŒ„
â”œâ”€â”€ yolov7tiny_baseline/     # å°ˆæ¡ˆç›®éŒ„
â”‚   â”œâ”€â”€ data/coco.yaml       # COCO é…ç½®æª”æ¡ˆ
â”‚   â”œâ”€â”€ train.py             # è¨“ç·´è…³æœ¬
â”‚   â””â”€â”€ ...
â””â”€â”€ coco/                    # COCO è³‡æ–™é›† (èˆ‡å°ˆæ¡ˆå¹³è¡Œ)
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ train2017/       # è¨“ç·´åœ–ç‰‡
    â”‚   â””â”€â”€ val2017/         # é©—è­‰åœ–ç‰‡
    â””â”€â”€ labels/
        â”œâ”€â”€ train2017/       # è¨“ç·´æ¨™ç±¤
        â””â”€â”€ val2017/         # é©—è­‰æ¨™ç±¤
```

### COCO è³‡æ–™é›†æº–å‚™

#### æ–¹å¼ 1: è‡ªå‹•ä¸‹è¼‰ (æ¨è–¦)
```bash
# ä½¿ç”¨å®˜æ–¹è…³æœ¬ä¸‹è¼‰
bash scripts/get_coco.sh
```

#### æ–¹å¼ 2: æ‰‹å‹•ä¸‹è¼‰
1. ä¸‹è¼‰ COCO2017 è³‡æ–™é›†ï¼š
   - [è¨“ç·´åœ–ç‰‡](http://images.cocodataset.org/zips/train2017.zip)
   - [é©—è­‰åœ–ç‰‡](http://images.cocodataset.org/zips/val2017.zip)
   - [æ¨™ç±¤](http://images.cocodataset.org/annotations/annotations_trainval2017.zip)

2. è§£å£“ä¸¦æ•´ç†ç›®éŒ„çµæ§‹

#### æ–¹å¼ 3: é è™•ç† 320x320 ç‰ˆæœ¬
å¦‚æœæ‚¨æœ‰é è™•ç†çš„ 320x320 ç‰ˆæœ¬ï¼š
```bash
# ç¢ºä¿è·¯å¾‘æ­£ç¢ºæŒ‡å‘é è™•ç†ç‰ˆæœ¬
# ä¿®æ”¹ data/coco.yaml ä¸­çš„è·¯å¾‘è¨­å®š
```

### è¨­å®šé©—è­‰

åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ç¢ºèªè³‡æ–™é›†è¨­å®šæ­£ç¢ºï¼š
```bash
python -c "
from utils.datasets import create_dataloader
from utils.general import check_dataset
check_dataset('data/coco.yaml')
print('è³‡æ–™é›†é©—è­‰å®Œæˆï¼')
"
```

---

## ğŸ¯ åŸºç¤è¨“ç·´

### å¿«é€Ÿé–‹å§‹

#### åŸºæœ¬è¨“ç·´æŒ‡ä»¤
```bash
# ä½¿ç”¨ PRD v1.4 è¦å®šçš„æ¨™æº–åƒæ•¸
python train.py \
  --img 320 \
  --batch 128 \
  --epochs 300 \
  --data data/coco.yaml \
  --weights '' \
  --hyp data/hyp.scratch.tiny.yaml \
  --device 0 \
  --workers 4 \
  --amp \
  --save-period 25
```

#### å¤š GPU è¨“ç·´
```bash
# ä½¿ç”¨ DataParallel (å–®æ©Ÿå¤šå¡)
python train.py \
  --img 320 \
  --batch 256 \
  --epochs 300 \
  --data data/coco.yaml \
  --weights '' \
  --hyp data/hyp.scratch.tiny.yaml \
  --device 0,1,2,3 \
  --workers 8 \
  --amp \
  --save-period 25

# ä½¿ç”¨ DistributedDataParallel (å»ºè­°)
python -m torch.distributed.launch --nproc_per_node=4 train.py \
  --img 320 \
  --batch 64 \
  --epochs 300 \
  --data data/coco.yaml \
  --weights '' \
  --hyp data/hyp.scratch.tiny.yaml \
  --device 0,1,2,3 \
  --workers 8 \
  --amp \
  --save-period 25 \
  --sync-bn
```

### é‡è¦åƒæ•¸èªªæ˜

| åƒæ•¸ | èªªæ˜ | PRD è¦ç¯„ | å¯èª¿æ•´ |
|------|------|----------|--------|
| `--img` | è¼¸å…¥åœ–ç‰‡å°ºå¯¸ | 320 | âŒ å›ºå®š |
| `--batch` | æ‰¹æ¬¡å¤§å° | ä¾ GPU èª¿æ•´ | âœ… å¯èª¿ |
| `--epochs` | è¨“ç·´è¼ªæ•¸ | 300 | âŒ å›ºå®š |
| `--data` | è³‡æ–™é›†é…ç½® | data/coco.yaml | âŒ å›ºå®š |
| `--weights` | åˆå§‹æ¬Šé‡ | '' (éš¨æ©Ÿ) | âŒ å›ºå®š |
| `--hyp` | è¶…åƒæ•¸æª”æ¡ˆ | hyp.scratch.tiny.yaml | âŒ å›ºå®š |
| `--amp` | æ··åˆç²¾åº¦ | é–‹å•Ÿ | âŒ å›ºå®š |
| `--workers` | è³‡æ–™è¼‰å…¥ç¨‹åº | ä¾ç³»çµ±èª¿æ•´ | âœ… å¯èª¿ |
| `--device` | ä½¿ç”¨çš„ GPU | 0 æˆ– 0,1,2,3 | âœ… å¯èª¿ |

### è¨“ç·´ç›£æ§

#### TensorBoard
è¨“ç·´è‡ªå‹•å•Ÿç”¨ TensorBoard è¨˜éŒ„ï¼š
```bash
# åœ¨å¦ä¸€å€‹çµ‚ç«¯åŸ·è¡Œ
tensorboard --logdir runs/train
# ç€è¦½å™¨é–‹å•Ÿ: http://localhost:6006
```

#### å³æ™‚æ—¥èªŒ
è¨“ç·´éç¨‹ä¸­æœƒé¡¯ç¤ºï¼š
```
Epoch    GPU_mem   box_loss   obj_loss   cls_loss   Instances       Size
   0/299      4.42G     0.0576     0.0614     0.0294        89        320: 100%|â–ˆâ–ˆ| 929/929
               Class     Images  Instances          P          R      mAP50   mAP50-95
                 all       5000      36335      0.693      0.538      0.605      0.377
```

### è¨“ç·´çµæœ

å®Œæˆçš„è¨“ç·´æœƒåœ¨ `runs/train/exp/` ç”¢ç”Ÿï¼š
- `weights/best.pt` - æœ€ä½³æ¨¡å‹æ¬Šé‡
- `weights/last.pt` - æœ€çµ‚æ¨¡å‹æ¬Šé‡
- `results.txt` - è¨“ç·´çµæœçµ±è¨ˆ
- `train_batch*.jpg` - è¨“ç·´æ¨£æœ¬å¯è¦–åŒ–
- `val_batch*.jpg` - é©—è­‰æ¨£æœ¬å¯è¦–åŒ–

---

## ğŸ§ª å¯¦é©—ç³»çµ±

### å¯¦é©—ç³»çµ±æ¦‚è¿°

å¯¦é©—ç³»çµ±æä¾›å®Œæ•´çš„å¤š GPU æ•ˆèƒ½æ¸¬è©¦ã€å¯¦é©—ç®¡ç†å’Œçµæœæ¯”è¼ƒåŠŸèƒ½ã€‚åŒ…å«å…©å€‹ç‰ˆæœ¬çš„ GPU æ¸¬è©¦å·¥å…·ï¼š
- **v1.0 åŸºç¤ç‰ˆ**: å¿«é€Ÿç°¡å–®æ¸¬è©¦ï¼ˆ10 ç§’å®Œæˆï¼‰
- **v2.0 æ“¬çœŸç‰ˆ**: å®Œæ•´å£“åŠ›æ¸¬è©¦ï¼ˆ15-20 åˆ†é˜ï¼‰

### GPU æ•ˆèƒ½æ¸¬è©¦ v2.0ï¼ˆæ“¬çœŸç‰ˆï¼‰

#### æ–°ç‰ˆç‰¹è‰²
- **çœŸå¯¦è³‡æ–™è¼‰å…¥**: æ•´åˆ COCO dataloader
- **å®Œæ•´ Loss è¨ˆç®—**: box_loss + obj_loss + cls_loss  
- **OOM é‚Šç•Œæ¢æ¸¬**: è‡ªå‹•å°‹æ‰¾æœ€å¤§å¯ç”¨ batch size
- **GPU ç›£æ§**: æº«åº¦ã€ä½¿ç”¨ç‡ã€è¨˜æ†¶é«”å³æ™‚è¿½è¹¤
- **å¤šç´šåˆ¥æ¸¬è©¦**: è¼•é‡(20æ¬¡)ã€ä¸­ç­‰(100æ¬¡)ã€é‡åº¦(200æ¬¡)

#### ç’°å¢ƒæº–å‚™
```bash
# å®‰è£å¿…è¦å¥—ä»¶
pip install gputil tqdm

# é©—è­‰ç’°å¢ƒï¼ˆç„¡éœ€ GPUï¼‰
python tools/gpu_benchmark_quick_test.py
```

#### å®Œæ•´æ“¬çœŸæ¸¬è©¦
```bash
# è‡ªå‹•åµæ¸¬ GPU ä¸¦åŸ·è¡Œå®Œæ•´æ¸¬è©¦
python tools/gpu_benchmark.py

# æŒ‡å®š GPU é¡å‹
python tools/gpu_benchmark.py --gpu-type H100

# å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ï¼ˆåƒ… light ç´šåˆ¥ï¼Œ2-3 åˆ†é˜ï¼‰
python tools/gpu_benchmark.py --quick

# è‡ªå®šç¾©æ¸¬è©¦ç´šåˆ¥
python tools/gpu_benchmark.py --test-levels light medium

# è·³é OOM æ¢æ¸¬
python tools/gpu_benchmark.py --no-find-limit
```

#### è·¨ GPU æ•ˆèƒ½æ¯”è¼ƒ
```bash
# å…ˆåŸ·è¡Œå„ GPU æ¸¬è©¦
python tools/gpu_benchmark.py --gpu-type RTX4090
python tools/gpu_benchmark.py --gpu-type H100
python tools/gpu_benchmark.py --gpu-type B200

# ç”Ÿæˆæ¯”è¼ƒå ±å‘Š
python tools/gpu_benchmark.py --compare RTX4090 H100 B200
```

#### æ¸¬è©¦æ™‚é–“é ä¼°
| GPU | æ¸¬è©¦æ¨¡å¼ | é ä¼°æ™‚é–“ | ç¸½è¿­ä»£æ•¸ |
|-----|----------|----------|----------|
| RTX 4090 | å¿«é€Ÿ | 2-3 åˆ†é˜ | ~1,000 æ¬¡ |
| RTX 4090 | å®Œæ•´ | 15-20 åˆ†é˜ | ~4,800 æ¬¡ |
| H100 | å¿«é€Ÿ | 1-2 åˆ†é˜ | ~1,500 æ¬¡ |
| H100 | å®Œæ•´ | 8-12 åˆ†é˜ | ~7,200 æ¬¡ |
| B200 | å®Œæ•´ | 6-10 åˆ†é˜ | ~9,600 æ¬¡ |

#### æ“¬çœŸæ¸¬è©¦çµæœç¯„ä¾‹
```
ğŸ† RTX4090 æ“¬çœŸæ•ˆèƒ½æ¸¬è©¦å ±å‘Š
================================================================================
ğŸ–¥ï¸  GPU: GeForce RTX 4090 (24GB)
ğŸ’» ç³»çµ±: 48 æ ¸å¿ƒ, 188.0GB RAM
ğŸ ç’°å¢ƒ: PyTorch 2.0.1+cu118, CUDA 11.8
ğŸ¯ æœ€å¤§ Batch Size: 768

Batch    Level    Status   Time/Batch   Memory     FPS      GPU%   Temp
--------------------------------------------------------------------------------
256      light    âœ…       0.123s       9.1GB      2088     95%    67Â°C
256      medium   âœ…       0.125s       9.1GB      2048     96%    69Â°C
256      heavy    âœ…       0.127s       9.1GB      2015     97%    71Â°C
384      light    âœ…       0.178s       13.2GB     2157     96%    68Â°C
384      medium   âœ…       0.181s       13.2GB     2121     97%    70Â°C
512      light    âœ…       0.234s       17.5GB     2188     97%    69Â°C
768      light    âœ…       0.342s       23.8GB     2245     98%    72Â°C
768      medium   âŒ       Out of Mem

ğŸ† æœ€ä½³æ•ˆèƒ½é…ç½®:
   Batch Size: 768 (light ç´šåˆ¥)
   æœ€é«˜ FPS: 2245
   è¨˜æ†¶é«”ä½¿ç”¨: 23.8GB
   GPU ä½¿ç”¨ç‡: 98%
```

### GPU æ•ˆèƒ½æ¸¬è©¦ v1.0ï¼ˆåŸºç¤ç‰ˆï¼‰

ä¿ç•™åŸå§‹å¿«é€Ÿæ¸¬è©¦åŠŸèƒ½ï¼š
```bash
# ä½¿ç”¨èˆŠç‰ˆæ¸¬è©¦ï¼ˆ10 ç§’å®Œæˆï¼‰
python tools/gpu_benchmark_v1.py
```

### å¯¦é©—ç®¡ç†

#### å»ºç«‹å¯¦é©—
```bash
# åŸºæœ¬å¯¦é©—
python tools/experiment_manager.py create --name baseline_test --gpu H100

# è‡ªå®šç¾© batch size
python tools/experiment_manager.py create --name large_batch --gpu H100 --batch 512

# èª¿æ•´å­¸ç¿’ç‡ (å€æ•¸èª¿æ•´)
python tools/experiment_manager.py create --name high_lr --gpu H100 --lr-mult 1.5

# èª¿æ•´é ç†±é€±æœŸ
python tools/experiment_manager.py create --name long_warmup --gpu H100 --warmup 10

# çµ„åˆèª¿æ•´
python tools/experiment_manager.py create \
  --name optimized_run \
  --gpu H100 \
  --batch 512 \
  --lr-mult 1.2 \
  --warmup 5
```

#### ç®¡ç†å¯¦é©—
```bash
# åˆ—å‡ºæ‰€æœ‰å¯¦é©—
python tools/experiment_manager.py list

# åŸ·è¡Œç‰¹å®šå¯¦é©—
python tools/experiment_manager.py run baseline_test_H100_20250814_120000
```

#### å¯¦é©—ç›®éŒ„çµæ§‹
```
experiments/
â”œâ”€â”€ experiments_log.json                    # å¯¦é©—ç¸½æ—¥èªŒ
â””â”€â”€ baseline_test_H100_20250814_120000/     # ç‰¹å®šå¯¦é©—
    â”œâ”€â”€ experiment_config.yaml              # å¯¦é©—é…ç½®
    â”œâ”€â”€ hyp_custom.yaml                     # è‡ªå®šç¾©è¶…åƒæ•¸ (å¦‚æœ‰)
    â”œâ”€â”€ run_experiment.sh                   # åŸ·è¡Œè…³æœ¬
    â”œâ”€â”€ monitoring/                         # ç›£æ§è³‡æ–™
    â”‚   â”œâ”€â”€ metrics_*.csv                   # è©³ç´°æŒ‡æ¨™
    â”‚   â””â”€â”€ summary_*.json                  # ç›£æ§æ‘˜è¦
    â””â”€â”€ [è¨“ç·´çµæœæª”æ¡ˆ]                       # æ¬Šé‡ã€æ—¥èªŒç­‰
```

### å¯¦é©—é…ç½®ç¯„ä¾‹

#### GPU é…ç½®æª”æ¡ˆ (configs/gpu_configs.yaml)
```yaml
gpu_configs:
  H100:
    name: "NVIDIA H100"
    memory_gb: 80
    optimal_batch_sizes: [256, 384, 512, 640]
    recommended_workers: 16
    mixed_precision: true
    compile_mode: true

base_training:
  img_size: 320
  epochs: 300
  data: "data/coco.yaml"
  weights: ""
  hyp: "data/hyp.scratch.tiny.yaml"
  amp: true
  save_period: 25
```

#### å¯¦é©—é…ç½®æª”æ¡ˆç¯„ä¾‹
```yaml
experiment_info:
  gpu_type: H100
  created_at: 2025-08-14T12:00:00
  prd_compliance: true
  base_spec: PRD v1.4

training_args:
  img_size: 320
  epochs: 300
  data: data/coco.yaml
  weights: ""
  hyp: experiments/baseline_test_H100_20250814_120000/hyp_custom.yaml
  batch: 512
  workers: 16
  device: 0
  amp: true
  save_period: 25
```

---

## ğŸ“Š ç›£æ§èˆ‡åˆ†æ

### å³æ™‚ç›£æ§

#### å•Ÿå‹•ç›£æ§
```bash
# ç›£æ§ç‰¹å®šå¯¦é©—
python tools/monitor_training.py --exp-name baseline_test_H100_20250814_120000

# è‡ªå®šç¾©ç›£æ§é–“éš” (ç§’)
python tools/monitor_training.py --exp-name your_exp --interval 10
```

#### ç›£æ§ä»‹é¢
```
[  45.3min] GPU: 95.2% VRAM: 78.5% (15234MB) Temp: 67.2Â°C CPU: 34.5% RAM: 18.7GB
```

### ç›£æ§æŒ‡æ¨™

#### GPU æŒ‡æ¨™
- **GPU ä½¿ç”¨ç‡**: è¨ˆç®—æ ¸å¿ƒä½¿ç”¨ç‡ç™¾åˆ†æ¯”
- **GPU è¨˜æ†¶é«”**: å·²ä½¿ç”¨ / ç¸½è¨˜æ†¶é«”
- **GPU æº«åº¦**: é‹è¡Œæº«åº¦ (Â°C)

#### ç³»çµ±æŒ‡æ¨™
- **CPU ä½¿ç”¨ç‡**: è™•ç†å™¨ä½¿ç”¨ç‡
- **RAM ä½¿ç”¨é‡**: ç³»çµ±è¨˜æ†¶é«”ä½¿ç”¨
- **ç£ç¢Ÿ I/O**: è®€å¯«é€Ÿç‡

#### ç›£æ§æª”æ¡ˆ
- `metrics_*.csv`: è©³ç´°çš„æ™‚åºç›£æ§è³‡æ–™
- `summary_*.json`: ç›£æ§æ‘˜è¦çµ±è¨ˆ

### çµæœæ¯”è¼ƒ

#### åŸºæœ¬æ¯”è¼ƒ
```bash
# åˆ—å°æ¯”è¼ƒæ‘˜è¦
python tools/compare_results.py

# åŒ¯å‡º Excel å ±å‘Š
python tools/compare_results.py --export-excel

# ç”Ÿæˆæ¯”è¼ƒåœ–è¡¨
python tools/compare_results.py --plot

# çµ„åˆä½¿ç”¨
python tools/compare_results.py --export-excel --plot --output detailed_analysis
```

#### æ¯”è¼ƒå ±å‘Šå…§å®¹
- **å¯¦é©—æ‘˜è¦è¡¨**: æ‰€æœ‰å¯¦é©—çš„é—œéµæŒ‡æ¨™
- **æ•ˆèƒ½å°æ¯”åœ–**: mAPã€è¨“ç·´æ™‚é–“ã€è³‡æºä½¿ç”¨
- **çµ±è¨ˆåˆ†æ**: å¹³å‡å€¼ã€æ¨™æº–å·®ã€æœ€ä½³çµæœ
- **Excel å ±å‘Š**: è©³ç´°çš„æ•¸æ“šè¡¨æ ¼

#### æ¯”è¼ƒæŒ‡æ¨™
- **æº–ç¢ºåº¦æŒ‡æ¨™**: mAP@0.5, mAP@0.5:0.95
- **æ•ˆèƒ½æŒ‡æ¨™**: è¨“ç·´æ™‚é–“ã€FPS
- **è³‡æºæŒ‡æ¨™**: GPU ä½¿ç”¨ç‡ã€è¨˜æ†¶é«”ä½¿ç”¨
- **ç³»çµ±æŒ‡æ¨™**: CPU ä½¿ç”¨ç‡ã€åŠŸè€—

### TensorBoard åˆ†æ

#### å•Ÿå‹• TensorBoard
```bash
# å–®ä¸€å¯¦é©—
tensorboard --logdir runs/train/exp

# å¤šå¯¦é©—æ¯”è¼ƒ
tensorboard --logdir runs/train

# æŒ‡å®šé€£æ¥åŸ 
tensorboard --logdir runs/train --port 6007
```

#### TensorBoard æŒ‡æ¨™
- **Loss æ›²ç·š**: box_loss, obj_loss, cls_loss
- **æº–ç¢ºåº¦æ›²ç·š**: mAP@0.5, mAP@0.5:0.95
- **å­¸ç¿’ç‡æ›²ç·š**: lr0, lr1, lr2
- **æ¨£æœ¬å¯è¦–åŒ–**: è¨“ç·´å’Œé©—è­‰æ¨£æœ¬

---

## ğŸ“¦ æ¨¡å‹å°å‡ºèˆ‡é‡åŒ–

### ONNX å°å‡º

#### åŸºæœ¬å°å‡º
```bash
# å°å‡ºç‚º ONNX æ ¼å¼
python export.py \
  --weights runs/train/exp/weights/best.pt \
  --img 320 320 \
  --batch 1 \
  --include onnx \
  --opset 13

# ç°¡åŒ–æ¨¡å‹
python -m onnxsim best.onnx best_simplified.onnx
```

#### é«˜éšå°å‡ºé¸é …
```bash
# å‹•æ…‹ batch size
python export.py \
  --weights best.pt \
  --img 320 320 \
  --batch 1 \
  --include onnx \
  --dynamic \
  --opset 13

# åŒ…å« NMS
python export.py \
  --weights best.pt \
  --img 320 320 \
  --batch 1 \
  --include onnx \
  --end2end \
  --opset 13
```

### PTQ é‡åŒ–

#### æº–å‚™æ ¡æ­£é›†
```bash
# ç”Ÿæˆæ ¡æ­£é›†æ¸…å–® (512 å¼µåœ–ç‰‡)
python tools/generate_calib_list.py \
  --dataset-path ../coco/images/val2017 \
  --output calib.txt \
  --count 512
```

#### åŸ·è¡Œ PTQ é‡åŒ–
```bash
# ONNX Runtime éœæ…‹é‡åŒ–
python tools/ort_ptq.py \
  --model best_simplified.onnx \
  --calib-list calib.txt \
  --output best_quantized.onnx \
  --quant-format QDQ
```

#### é‡åŒ–åƒæ•¸
- **æ¬Šé‡é‡åŒ–**: INT8, symmetric, per-channel
- **æ¿€æ´»é‡åŒ–**: INT8, asymmetric, per-tensor
- **æ ¡æ­£é›†**: 512 å¼µç„¡å¢å¼·åœ–ç‰‡
- **æ ¼å¼**: QDQ (Quantize-Dequantize)

### æ¨¡å‹è©•æ¸¬

#### åŸºæœ¬è©•æ¸¬
```bash
# FP16 æ¨¡å‹è©•æ¸¬
python test.py \
  --data data/coco.yaml \
  --img 320 \
  --batch 32 \
  --weights best.pt \
  --device 0

# ONNX æ¨¡å‹è©•æ¸¬
python tools/eval_onnx.py \
  --model best_simplified.onnx \
  --data data/coco.yaml \
  --img 320 \
  --batch 32
```

#### è©•æ¸¬åƒæ•¸ (PRD è¦å®š)
```bash
# ä½¿ç”¨æ¨™æº– NMS åƒæ•¸
--conf-thres 0.001 \
--iou-thres 0.65 \
--max-det 300
```

#### è©•æ¸¬çµæœè§£è®€
```
Class     Images  Instances        P        R    mAP50 mAP50-95
  all       5000      36335    0.693    0.538    0.605    0.377

Results saved to runs/test/exp/
```

### è·¨å¹³å°éƒ¨ç½²

#### æ”¯æ´çš„æ¨ç†å¼•æ“
- **ONNX Runtime**: CPU/GPU æ¨ç†
- **TensorRT**: NVIDIA GPU å„ªåŒ–
- **OpenVINO**: Intel ç¡¬é«”å„ªåŒ–
- **CoreML**: Apple è£ç½®éƒ¨ç½²

#### è½‰æ›ç¯„ä¾‹
```bash
# TensorRT è½‰æ›
trtexec --onnx=best_quantized.onnx \
        --saveEngine=best.trt \
        --fp16 \
        --workspace=1024

# OpenVINO è½‰æ›
mo --input_model best_quantized.onnx \
   --output_dir openvino_model
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. è¨˜æ†¶é«”ä¸è¶³ (OOM)
**ç¾è±¡**: `RuntimeError: CUDA out of memory`

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# 1. é™ä½ batch size
python tools/gpu_benchmark.py  # æ¸¬è©¦åˆé©çš„ batch size

# 2. æ¸›å°‘ workers
--workers 4  # æˆ–æ›´å°‘

# 3. ä½¿ç”¨æ¢¯åº¦ç´¯ç©
--accumulate 2  # ç´¯ç© 2 å€‹ batch å†æ›´æ–°

# 4. æ¸…ç† GPU è¨˜æ†¶é«”
python -c "import torch; torch.cuda.empty_cache()"
```

#### 2. è³‡æ–™è¼‰å…¥éŒ¯èª¤
**ç¾è±¡**: `FileNotFoundError` æˆ– `Image not found`

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# 1. æª¢æŸ¥è³‡æ–™é›†è·¯å¾‘
python -c "
from utils.general import check_dataset
check_dataset('data/coco.yaml')
"

# 2. é©—è­‰ coco.yaml è¨­å®š
cat data/coco.yaml

# 3. æª¢æŸ¥è³‡æ–™å¤¾çµæ§‹
ls ../coco/images/train2017/ | head -5
ls ../coco/labels/train2017/ | head -5
```

#### 3. è¨“ç·´é€Ÿåº¦æ…¢
**å¯èƒ½åŸå› èˆ‡è§£æ±ºæ–¹æ¡ˆ**:

```bash
# 1. æª¢æŸ¥ GPU ä½¿ç”¨ç‡
nvidia-smi

# 2. èª¿æ•´ workers æ•¸é‡
--workers 8  # æ ¹æ“š CPU æ ¸å¿ƒæ•¸èª¿æ•´

# 3. ä½¿ç”¨ SSD å„²å­˜è³‡æ–™
# å°‡è³‡æ–™é›†ç§»å‹•åˆ° SSD

# 4. æª¢æŸ¥ç¶²è·¯é »å¯¬ (å¦‚æœä½¿ç”¨ç¶²è·¯å„²å­˜)
# ä½¿ç”¨æœ¬åœ°å„²å­˜
```

#### 4. å¯¦é©—ç³»çµ±éŒ¯èª¤
**ç¾è±¡**: å¯¦é©—å»ºç«‹æˆ–åŸ·è¡Œå¤±æ•—

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# 1. æª¢æŸ¥ç›¸ä¾å¥—ä»¶
pip install GPUtil psutil matplotlib seaborn pandas openpyxl

# 2. æª¢æŸ¥ GPU åµæ¸¬
python -c "import GPUtil; print(GPUtil.getGPUs())"

# 3. æª¢æŸ¥ç›®éŒ„æ¬Šé™
chmod +x experiments/*/run_experiment.sh

# 4. æª¢æŸ¥ç£ç¢Ÿç©ºé–“
df -h
```

#### 5. TensorBoard ç„¡æ³•é–‹å•Ÿ
**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# 1. æª¢æŸ¥æ˜¯å¦å®‰è£
pip install tensorboard

# 2. æŒ‡å®šä¸åŒé€£æ¥åŸ 
tensorboard --logdir runs/train --port 6007

# 3. æª¢æŸ¥é˜²ç«ç‰†è¨­å®š
# é–‹æ”¾ 6006 é€£æ¥åŸ 

# 4. ä½¿ç”¨å…¬é–‹åœ°å€ (é›²ç«¯ç’°å¢ƒ)
tensorboard --logdir runs/train --host 0.0.0.0
```

### æ•ˆèƒ½å„ªåŒ–

#### GPU æ•ˆèƒ½å„ªåŒ–
```bash
# 1. ç¢ºä¿ä½¿ç”¨æœ€æ–°é©…å‹•
nvidia-smi

# 2. è¨­å®š GPU åŠŸè€—æ¨¡å¼
nvidia-smi -pm 1  # æŒçºŒæ¨¡å¼
nvidia-smi -pl 400  # è¨­å®šåŠŸç‡é™åˆ¶ (W)

# 3. æª¢æŸ¥ GPU æº«åº¦
nvidia-smi -q -d temperature

# 4. ä½¿ç”¨æ··åˆç²¾åº¦
--amp  # å·²åœ¨åŸºæœ¬æŒ‡ä»¤ä¸­åŒ…å«
```

#### ç³»çµ±æ•ˆèƒ½å„ªåŒ–
```bash
# 1. èª¿æ•´ç³»çµ±åƒæ•¸
echo 'net.core.rmem_max = 134217728' >> /etc/sysctl.conf
echo 'net.core.wmem_max = 134217728' >> /etc/sysctl.conf

# 2. è¨­å®š CPU è¦ªå’Œæ€§
taskset -c 0-7 python train.py ...

# 3. ä½¿ç”¨é«˜æ•ˆèƒ½æ¨¡å¼
echo performance > /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
```

### é™¤éŒ¯å·¥å…·

#### è¨“ç·´é™¤éŒ¯
```bash
# 1. å–®æ­¥é™¤éŒ¯
python train.py --debug --epochs 1

# 2. è³‡æ–™è¼‰å…¥æ¸¬è©¦
python -c "
from utils.datasets import create_dataloader
dataloader = create_dataloader('data/coco.yaml', 320, 32, 0, hyp=None)[0]
for i, (imgs, targets, paths, _) in enumerate(dataloader):
    print(f'Batch {i}: {imgs.shape}, {len(targets)} targets')
    if i >= 2: break
"

# 3. æ¨¡å‹å‰å‘æ¸¬è©¦
python -c "
import torch
from models.yolo import Model
model = Model('cfg/training/yolov7-tiny.yaml')
x = torch.randn(1, 3, 320, 320)
y = model(x)
print('Model output shapes:', [yi.shape for yi in y])
"
```

#### å¯¦é©—é™¤éŒ¯
```bash
# 1. æª¢æŸ¥å¯¦é©—é…ç½®
python tools/experiment_manager.py create --name debug_test --gpu RTX4090 --batch 64
cat experiments/debug_test_*/experiment_config.yaml

# 2. æ‰‹å‹•åŸ·è¡Œå¯¦é©—
cd experiments/debug_test_*
bash run_experiment.sh

# 3. æª¢æŸ¥ç›£æ§æ—¥èªŒ
python tools/monitor_training.py --exp-name debug_test --interval 1
```

---

## ğŸ“– é™„éŒ„

### A. PRD v1.4 è¦ç¯„å°ç…§è¡¨

| é …ç›® | PRD è¦æ±‚ | å¯¦ä½œç‹€æ…‹ | å‚™è¨» |
|------|----------|----------|------|
| æ¨¡å‹ | YOLOv7-tiny | âœ… å¯¦ä½œ | cfg/training/yolov7-tiny.yaml |
| è¼¸å…¥å°ºå¯¸ | 320Ã—320 | âœ… å¯¦ä½œ | --img 320 |
| è¨“ç·´ epoch | 300 | âœ… å¯¦ä½œ | --epochs 300 |
| åˆå§‹æ¬Šé‡ | éš¨æ©Ÿ | âœ… å¯¦ä½œ | --weights '' |
| è¶…åƒæ•¸æª”æ¡ˆ | hyp.scratch.tiny.yaml | âœ… å¯¦ä½œ | ä¸å¯ä¿®æ”¹ |
| AMP | å•Ÿç”¨ | âœ… å¯¦ä½œ | --amp |
| è³‡æ–™é›† | COCO2017 | âœ… å¯¦ä½œ | å®˜æ–¹ split |
| NMS åƒæ•¸ | å›ºå®š | âœ… å¯¦ä½œ | conf=0.001, iou=0.65 |
| PTQ æ ¼å¼ | QDQ | âœ… å¯¦ä½œ | ONNX Runtime |
| æ ¡æ­£é›† | 512 å¼µ | âœ… å¯¦ä½œ | ç„¡å¢å¼· |

### B. æª”æ¡ˆçµæ§‹åƒè€ƒ

```
yolov7tiny_baseline/
â”œâ”€â”€ CLAUDE.md                    # AI åŠ©æ‰‹æŒ‡ä»¤
â”œâ”€â”€ PRD v1.4.md                  # ç”¢å“éœ€æ±‚æ–‡ä»¶
â”œâ”€â”€ ä½¿ç”¨èªªæ˜æ›¸ v1.0.md            # æœ¬æ–‡ä»¶
â”œâ”€â”€ README_EXPERIMENT.md          # å¯¦é©—ç³»çµ±å¿«é€ŸæŒ‡å—
â”œâ”€â”€ requirements.txt              # Python ç›¸ä¾å¥—ä»¶
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ coco.yaml                # COCO è³‡æ–™é›†é…ç½®
â”‚   â””â”€â”€ hyp.scratch.tiny.yaml    # è¶…åƒæ•¸æª”æ¡ˆ (ä¸å¯ä¿®æ”¹)
â”œâ”€â”€ cfg/
â”‚   â””â”€â”€ training/
â”‚       â””â”€â”€ yolov7-tiny.yaml     # æ¨¡å‹é…ç½®
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ gpu_configs.yaml         # GPU é…ç½®æª”æ¡ˆ
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ gpu_benchmark.py         # GPU æ“¬çœŸæ•ˆèƒ½æ¸¬è©¦ v2.0
â”‚   â”œâ”€â”€ gpu_benchmark_v1.py      # GPU åŸºç¤æ¸¬è©¦ v1.0
â”‚   â”œâ”€â”€ gpu_benchmark_quick_test.py  # ç’°å¢ƒé©—è­‰å·¥å…·
â”‚   â”œâ”€â”€ experiment_manager.py    # å¯¦é©—ç®¡ç†ç³»çµ±
â”‚   â”œâ”€â”€ monitor_training.py      # è¨“ç·´ç›£æ§å·¥å…·
â”‚   â”œâ”€â”€ compare_results.py       # çµæœæ¯”è¼ƒå·¥å…·
â”‚   â””â”€â”€ ort_ptq.py              # PTQ é‡åŒ–å·¥å…·
â”œâ”€â”€ experiments/                 # å¯¦é©—çµæœç›®éŒ„
â”œâ”€â”€ runs/                        # è¨“ç·´è¼¸å‡ºç›®éŒ„
â”œâ”€â”€ train.py                     # è¨“ç·´è…³æœ¬
â”œâ”€â”€ export.py                    # æ¨¡å‹å°å‡ºè…³æœ¬
â”œâ”€â”€ test.py                      # æ¨¡å‹è©•æ¸¬è…³æœ¬
â””â”€â”€ utils/                       # å·¥å…·å‡½æ•¸
```

### C. æŒ‡ä»¤å¿«é€Ÿåƒè€ƒ

#### åŸºç¤æ“ä½œ
```bash
# åŸºæœ¬è¨“ç·´
python train.py --img 320 --batch 128 --epochs 300 --data data/coco.yaml --weights '' --hyp data/hyp.scratch.tiny.yaml --device 0 --workers 4 --amp --save-period 25

# æ¨¡å‹è©•æ¸¬
python test.py --data data/coco.yaml --img 320 --batch 32 --weights runs/train/exp/weights/best.pt

# ONNX å°å‡º
python export.py --weights runs/train/exp/weights/best.pt --img 320 320 --batch 1 --include onnx --opset 13
```

#### GPU æ“¬çœŸæ•ˆèƒ½æ¸¬è©¦ v2.0
```bash
# ç’°å¢ƒé©—è­‰
python tools/gpu_benchmark_quick_test.py

# å®Œæ•´æ“¬çœŸæ¸¬è©¦
python tools/gpu_benchmark.py

# å¿«é€Ÿæ¸¬è©¦ï¼ˆ2-3 åˆ†é˜ï¼‰
python tools/gpu_benchmark.py --quick

# æŒ‡å®š GPU å’Œæ¸¬è©¦ç´šåˆ¥
python tools/gpu_benchmark.py --gpu-type H100 --test-levels light medium

# è·¨ GPU æ•ˆèƒ½æ¯”è¼ƒ
python tools/gpu_benchmark.py --compare RTX4090 H100 B200

# èˆŠç‰ˆå¿«é€Ÿæ¸¬è©¦ï¼ˆ10 ç§’ï¼‰
python tools/gpu_benchmark_v1.py
```

#### å¯¦é©—ç®¡ç†
```bash
# å»ºç«‹å¯¦é©—
python tools/experiment_manager.py create --name test --gpu H100

# åˆ—å‡ºå¯¦é©—
python tools/experiment_manager.py list

# åŸ·è¡Œå¯¦é©—
python tools/experiment_manager.py run [å¯¦é©—ID]

# ç›£æ§è¨“ç·´
python tools/monitor_training.py --exp-name [å¯¦é©—ID]

# æ¯”è¼ƒçµæœ
python tools/compare_results.py --export-excel --plot
```

#### TensorBoard
```bash
# å•Ÿå‹• TensorBoard
tensorboard --logdir runs/train

# æŒ‡å®šé€£æ¥åŸ 
tensorboard --logdir runs/train --port 6007
```

### D. å¸¸ç”¨ç’°å¢ƒè®Šæ•¸

```bash
# CUDA ç›¸é—œ
export CUDA_VISIBLE_DEVICES=0,1,2,3
export CUDA_LAUNCH_BLOCKING=1  # é™¤éŒ¯ç”¨

# PyTorch ç›¸é—œ
export TORCH_HOME=/path/to/torch/cache
export PYTHONPATH=/path/to/yolov7tiny_baseline

# æ•ˆèƒ½å„ªåŒ–
export OMP_NUM_THREADS=8
export MKL_NUM_THREADS=8
```

### E. æŠ€è¡“æ”¯æ´

#### å•é¡Œå›å ±
å¦‚é‡åˆ°å•é¡Œï¼Œè«‹æä¾›ä»¥ä¸‹è³‡è¨Šï¼š
1. éŒ¯èª¤è¨Šæ¯å®Œæ•´å…§å®¹
2. ä½¿ç”¨çš„æŒ‡ä»¤
3. GPU å‹è™Ÿå’Œé©…å‹•ç‰ˆæœ¬
4. Python å’Œ PyTorch ç‰ˆæœ¬
5. ç³»çµ±ç’°å¢ƒ (OS, CUDA ç‰ˆæœ¬)

#### æ•ˆèƒ½åŸºæº–
ä¸åŒ GPU çš„åƒè€ƒæ•ˆèƒ½ (300 epochs)ï¼š

| GPU | Batch Size | è¨“ç·´æ™‚é–“ | mAP@0.5:0.95 | å‚™è¨» |
|-----|------------|----------|--------------|------|
| RTX 4090 | 256 | ~48h | 32.8 | æœ€ä½³æ€§åƒ¹æ¯” |
| RTX 5090 | 320 | ~36h | 33.1 | æ–°ä¸€ä»£æ¶æ§‹ |
| H100 | 512 | ~24h | 33.3 | ä¼æ¥­ç´šæ•ˆèƒ½ |
| B200 | 1024 | ~18h | 33.5 | é ‚ç´šæ•ˆèƒ½ |

*ä»¥ä¸Šæ•¸æ“šç‚ºåƒè€ƒå€¼ï¼Œå¯¦éš›çµæœå¯èƒ½å› ç³»çµ±é…ç½®è€Œç•°*

---

**æ–‡ä»¶ç‰ˆæœ¬**: v1.0  
**æœ€å¾Œæ›´æ–°**: 2025-08-14  
**ç¶­è­·**: YOLOv7-tiny Baseline å°ˆæ¡ˆåœ˜éšŠ

Â© 2025 YOLOv7-tiny Baseline Project. ä¿ç•™æ‰€æœ‰æ¬Šåˆ©ã€‚